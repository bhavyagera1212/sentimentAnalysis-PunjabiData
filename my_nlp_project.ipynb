{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b65c58",
      "metadata": {
        "id": "85b65c58"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83038801",
      "metadata": {
        "id": "83038801"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from unicodedata import normalize\n",
        "\n",
        "def punjabi_normalize(text, remove_nuktas=True, normalize_nasals=True):\n",
        "    \"\"\"\n",
        "    Custom normalization for Punjabi (Gurmukhi) text\n",
        "\n",
        "    Args:\n",
        "        text: Input Punjabi text\n",
        "        remove_nuktas: Whether to remove nuqta characters\n",
        "        normalize_nasals: Whether to normalize nasal marks\n",
        "\n",
        "    Returns:\n",
        "        Normalized Punjabi text\n",
        "    \"\"\"\n",
        "    # Normalize Unicode compositions\n",
        "    text = normalize('NFC', text)\n",
        "\n",
        "    # Common normalizations\n",
        "    replacements = {\n",
        "        # Normalize variations of the same character\n",
        "        '੍': '',  # Virama\n",
        "        '਼': '',   # Nukta if remove_nuktas=True\n",
        "\n",
        "        # Normalize quote marks\n",
        "        '“': '\"',\n",
        "        '”': '\"',\n",
        "        '‘': \"'\",\n",
        "        '’': \"'\",\n",
        "\n",
        "        # Normalize punctuation\n",
        "        '॥': '।',  # Double danda to single\n",
        "        '…': '...'\n",
        "    }\n",
        "\n",
        "    if remove_nuktas:\n",
        "        # Remove nukta from specific characters\n",
        "        nukta_map = {\n",
        "            'ਖ਼': 'ਖ',\n",
        "            'ਗ਼': 'ਗ',\n",
        "            'ਜ਼': 'ਜ',\n",
        "            'ਫ਼': 'ਫ',\n",
        "            'ੜ੍ਹ': 'ੜ੍ਹ'  # Special case\n",
        "        }\n",
        "        replacements.update(nukta_map)\n",
        "\n",
        "    if normalize_nasals:\n",
        "        # Normalize nasal marks\n",
        "        text = re.sub(r'([ਕ-ਹ])(ੰ|ਂ)', lambda m: m.group(1) + 'ੰ', text)\n",
        "\n",
        "    # Apply replacements\n",
        "    for old, new in replacements.items():\n",
        "        text = text.replace(old, new)\n",
        "\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e90baa9",
      "metadata": {
        "id": "7e90baa9"
      },
      "outputs": [],
      "source": [
        "def punjabi_tokenize(text, split_compound_words=True):\n",
        "    \"\"\"\n",
        "    Custom tokenizer for Punjabi text\n",
        "\n",
        "    Args:\n",
        "        text: Normalized Punjabi text\n",
        "        split_compound_words: Whether to split compound words\n",
        "\n",
        "    Returns:\n",
        "        List of tokens\n",
        "    \"\"\"\n",
        "    # Common Punjabi punctuation (add more as needed)\n",
        "    punc = set('।.,!?;:\"\\'()[]{}॥॰')\n",
        "\n",
        "    # Initialize tokens\n",
        "    tokens = []\n",
        "    current_token = []\n",
        "\n",
        "    for char in text:\n",
        "        if char.isspace() or char in punc:\n",
        "            if current_token:\n",
        "                tokens.append(''.join(current_token))\n",
        "                current_token = []\n",
        "            if char in punc:\n",
        "                tokens.append(char)\n",
        "        else:\n",
        "            # Handle compound words (optional)\n",
        "            if split_compound_words and char == '੍' and current_token:\n",
        "                tokens.append(''.join(current_token))\n",
        "                current_token = [char]\n",
        "            else:\n",
        "                current_token.append(char)\n",
        "\n",
        "    if current_token:\n",
        "        tokens.append(''.join(current_token))\n",
        "\n",
        "    # Post-processing\n",
        "    tokens = [t for t in tokens if t and not t.isspace()]\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc033133",
      "metadata": {
        "id": "fc033133"
      },
      "outputs": [],
      "source": [
        "def preprocess_punjabi(text, normalize=True, tokenize=True):\n",
        "    \"\"\"\n",
        "    Complete Punjabi text preprocessing pipeline\n",
        "\n",
        "    Args:\n",
        "        text: Raw Punjabi text\n",
        "        normalize: Whether to apply normalization\n",
        "        tokenize: Whether to tokenize\n",
        "\n",
        "    Returns:\n",
        "        Processed text (normalized string or token list)\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        text = punjabi_normalize(text)\n",
        "\n",
        "    if not tokenize:\n",
        "        return text\n",
        "\n",
        "    return punjabi_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e52c89c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e52c89c6",
        "outputId": "2df6165f-f820-4f8f-bb09-d9b785c6a29d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     sentence sentiment\n",
              "0  ਮੈਨੂੰ ਇਹ ਫਿਲਮ ਬਹੁਤ ਪਸੰਦ ਆਈ  positive\n",
              "1     ਅੱਜ ਦਾ ਦਿਨ ਬਹੁਤ ਮਾੜਾ ਸੀ  negative\n",
              "2      ਮੈਂ ਬੱਸ ਵਿੱਚ ਸਫ਼ਰ ਕੀਤਾ   neutral\n",
              "3             ਇਹ ਖਾਣਾ ਸੁਆਦ ਹੈ  positive\n",
              "4      ਮੇਰਾ ਸਿਰ ਬਹੁਤ ਦੁਖਦਾ ਹੈ  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8374f60-c318-4f60-b715-381a2201af79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ਮੈਨੂੰ ਇਹ ਫਿਲਮ ਬਹੁਤ ਪਸੰਦ ਆਈ</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ਅੱਜ ਦਾ ਦਿਨ ਬਹੁਤ ਮਾੜਾ ਸੀ</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ਮੈਂ ਬੱਸ ਵਿੱਚ ਸਫ਼ਰ ਕੀਤਾ</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ਇਹ ਖਾਣਾ ਸੁਆਦ ਹੈ</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ਮੇਰਾ ਸਿਰ ਬਹੁਤ ਦੁਖਦਾ ਹੈ</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8374f60-c318-4f60-b715-381a2201af79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8374f60-c318-4f60-b715-381a2201af79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8374f60-c318-4f60-b715-381a2201af79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b143556d-776c-4d6d-ac62-8b830be24cae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b143556d-776c-4d6d-ac62-8b830be24cae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b143556d-776c-4d6d-ac62-8b830be24cae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6498,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5113,\n        \"samples\": [\n          \"\\u0a1c\\u0a3f\\u0a2e \\u0a35\\u0a3f\\u0a71\\u0a1a \\u0a06\\u0a2a\\u0a23\\u0a47 \\u0a1f\\u0a40\\u0a1a\\u0a47 \\u0a28\\u0a42\\u0a70 \\u0a39\\u0a3e\\u0a38\\u0a32 \\u0a15\\u0a30\\u0a28 \\u0a32\\u0a08 \\u0a32\\u0a17\\u0a3e\\u0a24\\u0a3e\\u0a30 \\u0a2e\\u0a3f\\u0a39\\u0a28\\u0a24 \\u0a15\\u0a30\\u0a28\\u0a40 \\u0a2a\\u0a48\\u0a02\\u0a26\\u0a40 \\u0a39\\u0a48\",\n          \"\\u0a2b\\u0a3e\\u0a1c\\u0a3c\\u0a3f\\u0a32\\u0a15\\u0a3e \\u0a26\\u0a40 \\u0a38\\u0a30\\u0a39\\u0a71\\u0a26 '\\u0a24\\u0a47 \\u0a2b\\u0a4b\\u0a1f\\u0a4b \\u0a16\\u0a3f\\u0a71\\u0a1a\\u0a23 \\u0a26\\u0a40 \\u0a2e\\u0a28\\u0a3e\\u0a39\\u0a40 \\u0a39\\u0a48 \\u0a07\\u0a71\\u0a25\\u0a47\",\n          \"\\u0a2d\\u0a3e\\u0a30\\u0a24\\u0a40 \\u0a15\\u0a4d\\u0a30\\u0a3f\\u0a15\\u0a1f \\u0a1f\\u0a40\\u0a2e \\u0a28\\u0a47 \\u0a35\\u0a3f\\u0a38\\u0a3c\\u0a35 \\u0a15\\u0a71\\u0a2a \\u0a2b\\u0a3e\\u0a08\\u0a28\\u0a32 \\u0a35\\u0a3f\\u0a71\\u0a1a \\u0a38\\u0a3c\\u0a3e\\u0a28\\u0a26\\u0a3e\\u0a30 \\u0a1c\\u0a3f\\u0a71\\u0a24 \\u0a39\\u0a3e\\u0a38\\u0a32 \\u0a15\\u0a40\\u0a24\\u0a40 \\u0a39\\u0a48\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/punjabiData (1).csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Gu9Kvt1bn0KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a3a3f6-f997-4241-d720-fd5653d1de62"
      },
      "id": "Gu9Kvt1bn0KT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a26aee0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "8a26aee0",
        "outputId": "3f5cbaa9-f77d-4ced-a6c7-1dfc368542ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    2166\n",
              "negative    2166\n",
              "neutral     2166\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df[\"sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33565e40",
      "metadata": {
        "id": "33565e40"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def extract_vocabulary(texts, min_freq=5, max_freq = 50, max_words=None,\n",
        "                      remove_punct=True, remove_numbers=True):\n",
        "    \"\"\"\n",
        "    Extract vocabulary from a list of Punjabi texts\n",
        "\n",
        "    Args:\n",
        "        texts: List of Punjabi text strings\n",
        "        min_freq: Minimum frequency to include a word\n",
        "        max_words: Maximum number of words to return (None for all)\n",
        "        remove_punct: Whether to remove punctuation\n",
        "        remove_numbers: Whether to remove numbers\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of {word: frequency} sorted by frequency\n",
        "    \"\"\"\n",
        "    # Punjabi-specific punctuation (add more as needed)\n",
        "    punjabi_punct = set('।.,!?;:\"\\'()[]{}॥॰੦੧੨੩੪੫੬੭੮੯')\n",
        "\n",
        "    word_counts = Counter()\n",
        "\n",
        "    for text in texts:\n",
        "        # Tokenize (simple whitespace tokenizer)\n",
        "        words = text.split()\n",
        "\n",
        "        for word in words:\n",
        "            # Clean each word\n",
        "            if remove_punct:\n",
        "                word = ''.join(c for c in word if c not in punjabi_punct)\n",
        "            if remove_numbers:\n",
        "                word = re.sub(r'[੦-੯0-9]+', '', word)\n",
        "\n",
        "            # Add to counts if not empty\n",
        "            if word.strip():\n",
        "                word_counts[word] += 1\n",
        "\n",
        "    # Filter by frequency\n",
        "    vocab = {w: c for w, c in word_counts.items() if (c >= min_freq and c<=max_freq)}\n",
        "\n",
        "    # Sort by frequency (descending)\n",
        "    sorted_vocab = dict(sorted(vocab.items(), key=lambda x: -x[1]))\n",
        "\n",
        "    # Limit vocabulary size if requested\n",
        "    if max_words is not None:\n",
        "        sorted_vocab = dict(list(sorted_vocab.items())[:max_words])\n",
        "\n",
        "    return sorted_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3d1385b",
      "metadata": {
        "id": "a3d1385b"
      },
      "outputs": [],
      "source": [
        "vocab = extract_vocabulary(df[\"sentence\"].to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e1ab8f",
      "metadata": {
        "id": "a6e1ab8f"
      },
      "outputs": [],
      "source": [
        "vocab = list(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8bdf51e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8bdf51e",
        "outputId": "ff3e9e29-25c2-40d4-a061-e65a5e4e2091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1353"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c52103e",
      "metadata": {
        "id": "1c52103e"
      },
      "outputs": [],
      "source": [
        "df['sentence'] = df['sentence'].apply(preprocess_punjabi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857f6590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "857f6590",
        "outputId": "ebf96ea1-c915-4a77-82c7-516e9b0db7f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             [ਮੈਨੂੰ, ਇਹ, ਫਿਲਮ, ਬਹੁਤ, ਪਸੰਦ, ਆਈ]\n",
              "1                [ਅੱਜ, ਦਾ, ਦਿਨ, ਬਹੁਤ, ਮਾੜਾ, ਸੀ]\n",
              "2                   [ਮੈਂ, ਬੱਸ, ਵਿੱਚ, ਸਫਰ, ਕੀਤਾ]\n",
              "3                          [ਇਹ, ਖਾਣਾ, ਸੁਆਦ, ਹੈ]\n",
              "4                  [ਮੇਰਾ, ਸਿਰ, ਬਹੁਤ, ਦੁਖਦਾ, ਹੈ]\n",
              "5                      [ਉਹ, ਕੱਲਹ, ਸਹਿਰ, ਜਾਵੇਗਾ]\n",
              "6    [ਮੈਂ, ਆਪਣੇ, ਨਵੇਂ, ਘਰ, ਤੋਂ, ਬਹੁਤ, ਖੁਸ, ਹਾਂ]\n",
              "7        [ਟਰੈਫਿਕ, ਜਾਮ, ਕਾਰਨ, ਮੈਂ, ਲੇਟ, ਹੋ, ਗਿਆ]\n",
              "8             [ਅੱਜ, ਬਾਜਾਰ, ਵਿੱਚ, ਬਹੁਤ, ਭੀੜ, ਸੀ]\n",
              "9                   [ਮੈਨੂੰ, ਨੌਕਰੀ, ਮਿਲ, ਗਈ, ਹੈ]\n",
              "Name: sentence, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ਮੈਨੂੰ, ਇਹ, ਫਿਲਮ, ਬਹੁਤ, ਪਸੰਦ, ਆਈ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ਅੱਜ, ਦਾ, ਦਿਨ, ਬਹੁਤ, ਮਾੜਾ, ਸੀ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ਮੈਂ, ਬੱਸ, ਵਿੱਚ, ਸਫਰ, ਕੀਤਾ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ਇਹ, ਖਾਣਾ, ਸੁਆਦ, ਹੈ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ਮੇਰਾ, ਸਿਰ, ਬਹੁਤ, ਦੁਖਦਾ, ਹੈ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[ਉਹ, ਕੱਲਹ, ਸਹਿਰ, ਜਾਵੇਗਾ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[ਮੈਂ, ਆਪਣੇ, ਨਵੇਂ, ਘਰ, ਤੋਂ, ਬਹੁਤ, ਖੁਸ, ਹਾਂ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[ਟਰੈਫਿਕ, ਜਾਮ, ਕਾਰਨ, ਮੈਂ, ਲੇਟ, ਹੋ, ਗਿਆ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[ਅੱਜ, ਬਾਜਾਰ, ਵਿੱਚ, ਬਹੁਤ, ਭੀੜ, ਸੀ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[ਮੈਨੂੰ, ਨੌਕਰੀ, ਮਿਲ, ਗਈ, ਹੈ]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df['sentence'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e63baed1",
      "metadata": {
        "id": "e63baed1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4418425",
      "metadata": {
        "id": "a4418425"
      },
      "outputs": [],
      "source": [
        "sentences = df[\"sentence\"].to_list()\n",
        "labels = df[\"sentiment\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b944f86e",
      "metadata": {
        "id": "b944f86e"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75cb8470",
      "metadata": {
        "id": "75cb8470"
      },
      "outputs": [],
      "source": [
        "max_len = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015e8d3c",
      "metadata": {
        "id": "015e8d3c"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "labels_categorical = to_categorical(labels_encoded, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c4d1c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9c4d1c9",
        "outputId": "a2a2a62c-149f-45a8-cd04-eed1cff3f592"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = (X_train, y_train)\n",
        "test_data = (X_test, y_test)"
      ],
      "metadata": {
        "id": "bVWZPwGoP56i"
      },
      "id": "bVWZPwGoP56i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ca84ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ca84ab",
        "outputId": "23397fc1-d294-4eb9-9b2a-8d64a2a6478e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 2, output_dim=128, input_length=max_len))\n",
        "model.add(LSTM(64)),\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f474c6",
      "metadata": {
        "id": "b3f474c6"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92c27c13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92c27c13",
        "outputId": "b61f2576-487c-4fac-ece8-c535c9e974d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.3783 - loss: 1.0930 - val_accuracy: 0.4453 - val_loss: 1.0652\n",
            "Epoch 2/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.4992 - loss: 1.0034 - val_accuracy: 0.5124 - val_loss: 0.9745\n",
            "Epoch 3/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.6091 - loss: 0.8376 - val_accuracy: 0.5998 - val_loss: 0.8472\n",
            "Epoch 4/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.6622 - loss: 0.7695 - val_accuracy: 0.6127 - val_loss: 0.8659\n",
            "Epoch 5/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.6564 - loss: 0.7630 - val_accuracy: 0.6053 - val_loss: 0.8213\n",
            "Epoch 6/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.6964 - loss: 0.6924 - val_accuracy: 0.6734 - val_loss: 0.7869\n",
            "Epoch 7/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7418 - loss: 0.6413 - val_accuracy: 0.6854 - val_loss: 0.7496\n",
            "Epoch 8/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7722 - loss: 0.5804 - val_accuracy: 0.6900 - val_loss: 0.7758\n",
            "Epoch 9/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.7940 - loss: 0.5667 - val_accuracy: 0.6992 - val_loss: 0.7583\n",
            "Epoch 10/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.8020 - loss: 0.5128 - val_accuracy: 0.7249 - val_loss: 0.6651\n",
            "Epoch 11/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.8064 - loss: 0.5217 - val_accuracy: 0.7010 - val_loss: 0.7539\n",
            "Epoch 12/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.8319 - loss: 0.4470 - val_accuracy: 0.7433 - val_loss: 0.6844\n",
            "Epoch 13/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8286 - loss: 0.4758 - val_accuracy: 0.7452 - val_loss: 0.6708\n",
            "Epoch 14/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.8575 - loss: 0.3832 - val_accuracy: 0.7461 - val_loss: 0.6543\n",
            "Epoch 15/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.8711 - loss: 0.3418 - val_accuracy: 0.7461 - val_loss: 0.6907\n",
            "Epoch 16/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.8769 - loss: 0.3374 - val_accuracy: 0.7562 - val_loss: 0.6772\n",
            "Epoch 17/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.8821 - loss: 0.3248 - val_accuracy: 0.7571 - val_loss: 0.6685\n",
            "Epoch 18/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.8887 - loss: 0.3033 - val_accuracy: 0.7571 - val_loss: 0.6767\n",
            "Epoch 19/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.8795 - loss: 0.3283 - val_accuracy: 0.7516 - val_loss: 0.7166\n",
            "Epoch 20/20\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.8916 - loss: 0.2839 - val_accuracy: 0.7507 - val_loss: 0.6845\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eeaa4693690>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=20, validation_data = test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a94ff3",
      "metadata": {
        "id": "a4a94ff3",
        "outputId": "050c742e-7d12-4c21-ec15-7f087e151d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "97\n"
          ]
        }
      ],
      "source": [
        "# testing on positive sentences\n",
        "test_sentence = pd.read_csv(\"punjabi_positive_sentences.csv\")\n",
        "test_sentence = test_sentence[\"sentence\"].to_list()\n",
        "test_seq = tokenizer.texts_to_sequences(test_sentence)\n",
        "test_pad = pad_sequences(test_seq, maxlen=max_len, padding='post')\n",
        "pred = model.predict(test_pad)\n",
        "predictions = [np.argmax(p) for p in pred]\n",
        "# pred_label = label_encoder.inverse_transform([np.argmax(pred)])\n",
        "# print(\"Prediction:\", pred_label)\n",
        "print(len(test_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e94b7fb",
      "metadata": {
        "id": "5e94b7fb",
        "outputId": "8e17caa1-3825-465c-9f77-fe64100af5d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({np.str_('positive'): 83,\n",
              "         np.str_('neutral'): 8,\n",
              "         np.str_('negative'): 6})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "res = np.array(label_encoder.inverse_transform(predictions))\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "ctr = Counter(res)\n",
        "\n",
        "ctr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying BERT"
      ],
      "metadata": {
        "id": "NgYf9Mb7qYCS"
      },
      "id": "NgYf9Mb7qYCS"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "UQbROd3mnoPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35652f1-26ca-40c9-8c56-fd00365c0dc4"
      },
      "id": "UQbROd3mnoPU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "JGRKUEMesOiz"
      },
      "id": "JGRKUEMesOiz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/muril-base-cased\"  # or \"ai4bharat/indic-bert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R271gXIlsUwK",
        "outputId": "7f471833-6dc5-4bc9-d5ef-01e9e5b6bdb4"
      },
      "id": "R271gXIlsUwK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"combined.csv\")"
      ],
      "metadata": {
        "id": "rR_79MqlsVMO"
      },
      "id": "rR_79MqlsVMO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"sentence\"].tolist(),\n",
        "    df[\"sentiment\"].tolist(),\n",
        "    test_size=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "TzwxBUcLt-CK"
      },
      "id": "TzwxBUcLt-CK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
      ],
      "metadata": {
        "id": "mS0bw7H9uBkU"
      },
      "id": "mS0bw7H9uBkU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class PunjabiSentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item, self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = PunjabiSentimentDataset(train_encodings, train_labels)\n",
        "val_dataset = PunjabiSentimentDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "BOcpSDzUuDYa"
      },
      "id": "BOcpSDzUuDYa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "XBQFWEP5uFOc",
        "outputId": "101bfc32-e2a6-48ea-faea-05dde76af638"
      },
      "id": "XBQFWEP5uFOc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "vars() argument must have __dict__ attribute",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-27eba98659fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2512\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5242\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5243\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5244\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5245\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mdefault_data_collator\u001b[0;34m(features, return_tensors)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_default_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "print(results)"
      ],
      "metadata": {
        "id": "cPBnvgkauSTc"
      },
      "id": "cPBnvgkauSTc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "model.save_pretrained(\"./punjabi_sentiment_model\")\n",
        "tokenizer.save_pretrained(\"./punjabi_sentiment_model\")\n",
        "\n",
        "# Load later\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"./punjabi_sentiment_model\",\n",
        "    tokenizer=\"./punjabi_sentiment_model\"\n",
        ")\n",
        "\n",
        "# Predict\n",
        "result = classifier(\"ਮੈਨੂੰ ਇਹ ਫਿਲਮ ਬਹੁਤ ਪਸੰਦ ਆਈ\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YnGMJFJnuc_3"
      },
      "id": "YnGMJFJnuc_3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}